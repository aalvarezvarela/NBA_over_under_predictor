{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification NBA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from nba_ou.data_preparation.missing_data.handle_missing_data import (\n",
    "    apply_missing_policy,\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import KFold, cross_validate, train_test_split\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1628016/2663114250.py:6: DtypeWarning: Columns (204,205,206,207,247,248,249,250,290,291,292,293,333,334,335,336,376,377,378,379,419,420,421,422,615,616,617,618,658,659,660,661,701,702,703,704,744,745,746,747,787,788,789,790,830,831,832,833) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_stats = pd.read_csv(path)\n",
      "/tmp/ipykernel_1628016/2663114250.py:10: DtypeWarning: Columns (204,205,206,207,247,248,249,250,290,291,292,293,333,334,335,336,376,377,378,379,419,420,421,422,615,616,617,618,658,659,660,661,701,702,703,704,744,745,746,747,787,788,789,790,830,831,832,833) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_stats = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/adrian_alvarez/Projects/NBA_over_under_predictor/data/train_data/\"\n",
    "name = \"all_odds_training_data_until_20260110.csv\"\n",
    "\n",
    "path = data_path + name\n",
    "\n",
    "df_stats = pd.read_csv(path)\n",
    "\n",
    "dtype_dict = {col: str for col in df_stats.columns if \"ID\" in col.upper()}\n",
    "\n",
    "df_stats = pd.read_csv(\n",
    "    path,\n",
    "    dtype=dtype_dict\n",
    ")\n",
    "df_stats['GAME_DATE'] = pd.to_datetime(df_stats['GAME_DATE']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print column names with name in lower case\n",
    "# for col in df_stats.columns:\n",
    "#     if not col.isupper():\n",
    "#         print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING DATAFRAME CLEANING PIPELINE\n",
      "================================================================================\n",
      "Starting basic cleaning with 10794 rows\n",
      "Basic cleaning complete: 7976 rows remaining\n",
      "\n",
      "Starting advanced column cleaning with 1133 columns\n",
      "\n",
      "Advanced column cleaning complete: 1133 â†’ 660 columns (473 removed)\n",
      "\n",
      "\n",
      "Applying missing data policy...\n",
      "\n",
      "Missing Data Policy Report:\n",
      "  Rows dropped: 0 (0.0%)\n",
      "  Critical columns requiring data: 5\n",
      "  Columns zero-filled: 132\n",
      "  Infer pairs applied: 54/228\n",
      "  Remaining NaN cells: 144\n",
      "\n",
      "Dropping rows that are all NaN...\n",
      "================================================================================\n",
      "CLEANING COMPLETE\n",
      "Final shape: (7957, 660)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from nba_ou.data_preparation.missing_data.clean_df_for_training import (\n",
    "    clean_dataframe_for_training\n",
    ")\n",
    "df_to_train = clean_dataframe_for_training(df_stats, nan_threshold=4, drop_all_na_rows=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Column",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "NA_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NA_Percentage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Most_Common_Season_Year",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5053d66b-0da1-4cbf-b229-c40319219fa9",
       "rows": [],
       "shape": {
        "columns": 4,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>NA_Count</th>\n",
       "      <th>NA_Percentage</th>\n",
       "      <th>Most_Common_Season_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Column, NA_Count, NA_Percentage, Most_Common_Season_Year]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count NAs per column\n",
    "na_counts = df_to_train.isna().sum()\n",
    "\n",
    "# Get most common SEASON_YEAR for nulls in each column\n",
    "most_common_season = []\n",
    "for col in df_to_train.columns:\n",
    "    if na_counts[col] > 0:\n",
    "        # Get rows where this column is null\n",
    "        null_rows = df_stats[df_stats[col].isna()]\n",
    "        if len(null_rows) > 0 and 'SEASON_YEAR' in df_stats.columns:\n",
    "            # Find most common SEASON_YEAR for these null rows\n",
    "            common_season = null_rows['SEASON_YEAR'].mode()\n",
    "            most_common_season.append(common_season.iloc[0] if len(common_season) > 0 else None)\n",
    "        else:\n",
    "            most_common_season.append(None)\n",
    "    else:\n",
    "        most_common_season.append(None)\n",
    "\n",
    "na_counts_df = pd.DataFrame({\n",
    "    'Column': na_counts.index,\n",
    "    'NA_Count': na_counts.values,\n",
    "    'NA_Percentage': (na_counts.values / len(df_to_train) * 100).round(2),\n",
    "    'Most_Common_Season_Year': most_common_season\n",
    "}).sort_values('NA_Count', ascending=False)\n",
    "\n",
    "# Show only columns with NAs\n",
    "na_counts_df[na_counts_df['NA_Count'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_to_train.drop(['TOTAL_POINTS', 'SEASON_YEAR'], axis=1, errors='ignore')\n",
    "y = df_to_train['TOTAL_POINTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_train['IS_TRAINING_DATA'] = False\n",
    "\n",
    "# Mark True for the rows in the training set\n",
    "df_to_train.loc[X_train.index, 'IS_TRAINING_DATA'] = True\n",
    "# output_name = f\"{data_path}/training_data_with_missing_data_handled_from_2004-10-01_to_2026-01-10_classifier.csv\"\n",
    "# df_to_train.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5896\n",
      "Test set size: 1966\n",
      "Number of columns in training set: 658\n",
      "Number of columns in test set: 658\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "# Check number of coulmns\n",
    "print(f\"Number of columns in training set: {X_train.shape[1]}\")\n",
    "print(f\"Number of columns in test set: {X_test.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scorer for over/under betting accuracy\n",
    "def over_under_betting_accuracy(y_true, y_pred, betting_line):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of over/under betting decisions.\n",
    "    \n",
    "    A bet is successful if:\n",
    "    - We predict OVER (pred > line) and actual is OVER (true > line), OR\n",
    "    - We predict UNDER (pred < line) and actual is UNDER (true < line)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Actual total points\n",
    "    y_pred : array-like\n",
    "        Predicted total points\n",
    "    betting_line : array-like\n",
    "        Over/under betting line\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Accuracy of betting decisions (0 to 1)\n",
    "    \"\"\"\n",
    "    # Calculate differences from the betting line\n",
    "    pred_diff = y_pred - betting_line\n",
    "    true_diff = y_true - betting_line\n",
    "    \n",
    "    # Check if both have the same sign (both positive or both negative)\n",
    "    # np.sign returns -1, 0, or 1\n",
    "    correct_predictions = np.sign(pred_diff) == np.sign(true_diff)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(correct_predictions)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Custom scorer class to work with sklearn\n",
    "class OverUnderScorer:\n",
    "    \"\"\"\n",
    "    Custom scorer that calculates betting accuracy for over/under predictions.\n",
    "    \"\"\"\n",
    "    def __call__(self, estimator, X, y_true):\n",
    "        \"\"\"\n",
    "        Calculate the over/under betting accuracy.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        estimator : fitted estimator\n",
    "            The model to evaluate\n",
    "        X : DataFrame\n",
    "            Features including 'TOTAL_OVER_UNDER_LINE'\n",
    "        y_true : array-like\n",
    "            Actual total points\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        float : Betting accuracy score\n",
    "        \"\"\"\n",
    "        y_pred = estimator.predict(X)\n",
    "        betting_line = X['TOTAL_OVER_UNDER_LINE'].values\n",
    "        return over_under_betting_accuracy(y_true, y_pred, betting_line)\n",
    "\n",
    "\n",
    "# Create a scorer object\n",
    "over_under_scorer = OverUnderScorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare scores to be used\n",
    "scoring = {\n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'RMSE': make_scorer(root_mean_squared_error),\n",
    "    'MAE': make_scorer(mean_absolute_error),\n",
    "    'OU_Betting_Accuracy': over_under_scorer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(cv_results):\n",
    "    for sc in scoring.keys():\n",
    "        if sc == 'OU_Betting_Accuracy':\n",
    "            print(f'Train {sc}:', f\"{cv_results[f'train_{sc}'].mean():.2%}\")\n",
    "            print(f'Validation {sc}:', f\"{cv_results[f'test_{sc}'].mean():.2%}\")\n",
    "        else:\n",
    "            print(f'Train {sc}:', cv_results[f'train_{sc}'].mean().round(5))\n",
    "            print(f'Validation {sc}:', cv_results[f'test_{sc}'].mean().round(5))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_vs_pred(model, X_train, y_train):\n",
    "    preds = cross_val_predict(model, X_train, y_train, cv=kf, n_jobs=-1)\n",
    "    x_line = np.arange(y_train.min(), y_train.max())\n",
    "    plt.scatter(y_train, preds)\n",
    "    plt.plot(x_line, x_line, color='orange')\n",
    "    plt.xlabel('Real target')\n",
    "    plt.ylabel('Predicted target')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 382.54941\n",
      "Validation MSE: 382.92416\n",
      "\n",
      "Train RMSE: 19.5588\n",
      "Validation RMSE: 19.56739\n",
      "\n",
      "Train MAE: 15.5792\n",
      "Validation MAE: 15.58577\n",
      "\n",
      "Train OU_Betting_Accuracy: 49.56%\n",
      "Validation OU_Betting_Accuracy: 49.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "season_bl = DummyRegressor(strategy='mean')\n",
    "cv_results = cross_validate(season_bl, X_train, y_train, cv=kf,\n",
    "                            scoring=scoring, return_train_score=True)\n",
    "season_bl.fit(X_train, y_train)\n",
    "print_metrics(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 293.36\n",
      "RMSE: 17.13\n",
      "MAE: 13.65\n"
     ]
    }
   ],
   "source": [
    "# Baseline 3: Predict the betting line (TOTAL_OVER_UNDER_LINE)\n",
    "y_pred_baseline_3 = X_train['TOTAL_OVER_UNDER_LINE']\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_train, y_pred_baseline_3)\n",
    "mae = mean_absolute_error(y_train, y_pred_baseline_3)\n",
    "rmse = root_mean_squared_error(y_train, y_pred_baseline_3)\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 241.19421\n",
      "Validation MSE: 322.52042\n",
      "\n",
      "Train RMSE: 15.53039\n",
      "Validation RMSE: 17.95828\n",
      "\n",
      "Train MAE: 12.27892\n",
      "Validation MAE: 14.22338\n",
      "\n",
      "Train OU_Betting_Accuracy: 62.20%\n",
      "Validation OU_Betting_Accuracy: 51.13%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "cv_results = cross_validate(lr, X_train.fillna(0), y_train, cv=kf,\n",
    "                            scoring=scoring, return_train_score=True)\n",
    "\n",
    "print_metrics(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 159.04377\n",
      "Validation MSE: 287.48163\n",
      "\n",
      "Train RMSE: 12.61123\n",
      "Validation RMSE: 16.9545\n",
      "\n",
      "Train MAE: 10.0342\n",
      "Validation MAE: 13.44005\n",
      "\n",
      "Train OU_Betting_Accuracy: 80.07%\n",
      "Validation OU_Betting_Accuracy: 53.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Example XGBoost regressor:\n",
    "xgb_reg = XGBRegressor(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.02,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.5,       # Equivalent to max_samples in GBRegressor\n",
    "    colsample_bytree=0.6, # Equivalent to max_features in GBRegressor\n",
    "    n_jobs=-2,\n",
    "    random_state=16)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    xgb_reg, \n",
    "    X_train, y_train, \n",
    "    cv=kf, \n",
    "    scoring=scoring,      # Use your custom scoring or e.g. 'neg_mean_absolute_error'\n",
    "    return_train_score=True,\n",
    "    n_jobs=-2\n",
    ")\n",
    "# Train final model on full train set\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Print metrics\n",
    "print_metrics(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_710ef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_710ef_level0_col0\" class=\"col_heading level0 col0\" >threshold_abs_pred_minus_line_gt</th>\n",
       "      <th id=\"T_710ef_level0_col1\" class=\"col_heading level0 col1\" >n_games</th>\n",
       "      <th id=\"T_710ef_level0_col2\" class=\"col_heading level0 col2\" >pct_of_test</th>\n",
       "      <th id=\"T_710ef_level0_col3\" class=\"col_heading level0 col3\" >ou_betting_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_710ef_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_710ef_row0_col1\" class=\"data row0 col1\" >1990</td>\n",
       "      <td id=\"T_710ef_row0_col2\" class=\"data row0 col2\" >100.0%</td>\n",
       "      <td id=\"T_710ef_row0_col3\" class=\"data row0 col3\" >54.07%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_710ef_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_710ef_row1_col1\" class=\"data row1 col1\" >1544</td>\n",
       "      <td id=\"T_710ef_row1_col2\" class=\"data row1 col2\" >77.6%</td>\n",
       "      <td id=\"T_710ef_row1_col3\" class=\"data row1 col3\" >54.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_710ef_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_710ef_row2_col1\" class=\"data row2 col1\" >1147</td>\n",
       "      <td id=\"T_710ef_row2_col2\" class=\"data row2 col2\" >57.6%</td>\n",
       "      <td id=\"T_710ef_row2_col3\" class=\"data row2 col3\" >55.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_710ef_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_710ef_row3_col1\" class=\"data row3 col1\" >803</td>\n",
       "      <td id=\"T_710ef_row3_col2\" class=\"data row3 col2\" >40.4%</td>\n",
       "      <td id=\"T_710ef_row3_col3\" class=\"data row3 col3\" >56.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_710ef_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_710ef_row4_col1\" class=\"data row4 col1\" >545</td>\n",
       "      <td id=\"T_710ef_row4_col2\" class=\"data row4 col2\" >27.4%</td>\n",
       "      <td id=\"T_710ef_row4_col3\" class=\"data row4 col3\" >60.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_710ef_row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "      <td id=\"T_710ef_row5_col1\" class=\"data row5 col1\" >367</td>\n",
       "      <td id=\"T_710ef_row5_col2\" class=\"data row5 col2\" >18.4%</td>\n",
       "      <td id=\"T_710ef_row5_col3\" class=\"data row5 col3\" >63.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_710ef_row6_col0\" class=\"data row6 col0\" >6</td>\n",
       "      <td id=\"T_710ef_row6_col1\" class=\"data row6 col1\" >233</td>\n",
       "      <td id=\"T_710ef_row6_col2\" class=\"data row6 col2\" >11.7%</td>\n",
       "      <td id=\"T_710ef_row6_col3\" class=\"data row6 col3\" >67.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_710ef_row7_col0\" class=\"data row7 col0\" >7</td>\n",
       "      <td id=\"T_710ef_row7_col1\" class=\"data row7 col1\" >149</td>\n",
       "      <td id=\"T_710ef_row7_col2\" class=\"data row7 col2\" >7.5%</td>\n",
       "      <td id=\"T_710ef_row7_col3\" class=\"data row7 col3\" >72.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_710ef_row8_col0\" class=\"data row8 col0\" >8</td>\n",
       "      <td id=\"T_710ef_row8_col1\" class=\"data row8 col1\" >104</td>\n",
       "      <td id=\"T_710ef_row8_col2\" class=\"data row8 col2\" >5.2%</td>\n",
       "      <td id=\"T_710ef_row8_col3\" class=\"data row8 col3\" >77.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_710ef_row9_col0\" class=\"data row9 col0\" >9</td>\n",
       "      <td id=\"T_710ef_row9_col1\" class=\"data row9 col1\" >77</td>\n",
       "      <td id=\"T_710ef_row9_col2\" class=\"data row9 col2\" >3.9%</td>\n",
       "      <td id=\"T_710ef_row9_col3\" class=\"data row9 col3\" >79.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ef_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_710ef_row10_col0\" class=\"data row10 col0\" >10</td>\n",
       "      <td id=\"T_710ef_row10_col1\" class=\"data row10 col1\" >58</td>\n",
       "      <td id=\"T_710ef_row10_col2\" class=\"data row10 col2\" >2.9%</td>\n",
       "      <td id=\"T_710ef_row10_col3\" class=\"data row10 col3\" >82.76%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x775347e31dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ou_accuracy(y_true, y_pred, line):\n",
    "    \"\"\"\n",
    "    Same sign of (pred-line) and (true-line).\n",
    "    Note: pushes are counted as correct only if both are exactly 0 (rare with .5 lines).\n",
    "    \"\"\"\n",
    "    pred_diff = y_pred - line\n",
    "    true_diff = y_true - line\n",
    "    return np.mean(np.sign(pred_diff) == np.sign(true_diff))\n",
    "\n",
    "def evaluate_ou_thresholds(\n",
    "    model,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    line_col: str = \"TOTAL_OVER_UNDER_LINE\",\n",
    "    thresholds = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n",
    "):\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Line + margins\n",
    "    line = X_test[line_col].to_numpy()\n",
    "    margin = np.abs(y_pred - line)\n",
    "\n",
    "    rows = []\n",
    "    n_total = len(y_test)\n",
    "\n",
    "    # Full test set first (threshold 0 means \"all\")\n",
    "    for t in thresholds:\n",
    "        mask = margin > t\n",
    "        n = int(mask.sum())\n",
    "        if n == 0:\n",
    "            acc = np.nan\n",
    "        else:\n",
    "            acc = ou_accuracy(y_test.to_numpy()[mask], y_pred[mask], line[mask])\n",
    "\n",
    "        rows.append({\n",
    "            \"threshold_abs_pred_minus_line_gt\": t,\n",
    "            \"n_games\": n,\n",
    "            \"pct_of_test\": (n / n_total) if n_total else np.nan,\n",
    "            \"ou_betting_accuracy\": acc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows), y_pred\n",
    "\n",
    "\n",
    "\n",
    "results_df, y_pred_test = evaluate_ou_thresholds(\n",
    "    model=xgb_reg,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    thresholds=range(0, 11)  # 0..10\n",
    ")\n",
    "\n",
    "# Pretty display\n",
    "display(results_df.style.format({\n",
    "    \"pct_of_test\": \"{:.1%}\",\n",
    "    \"ou_betting_accuracy\": \"{:.2%}\",\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON_YEAR  n_games  ou_betting_accuracy  threshold_abs_pred_minus_line_gt\n",
      "0         2018        4             0.250000                               0.0\n",
      "1         2019      225             0.484444                               0.0\n",
      "2         2020      292             0.500000                               0.0\n",
      "3         2021      352             0.596591                               0.0\n",
      "4         2022      312             0.557692                               0.0\n",
      "5         2023      297             0.558923                               0.0\n",
      "6         2024      363             0.490358                               0.0\n",
      "7         2025      145             0.634483                               0.0\n"
     ]
    }
   ],
   "source": [
    "def add_ou_correctness_columns(\n",
    "    model,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    line_col: str = \"TOTAL_OVER_UNDER_LINE\",\n",
    ") -> pd.DataFrame:\n",
    "    df = X_test.copy()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    line = df[line_col].to_numpy()\n",
    "    y_true = y_test.to_numpy()\n",
    "\n",
    "    pred_diff = y_pred - line\n",
    "    true_diff = y_true - line\n",
    "\n",
    "    df[\"Y_TRUE\"] = y_true\n",
    "    df[\"Y_PRED\"] = y_pred\n",
    "    df[\"LINE\"] = line\n",
    "    df[\"PRED_DIFF\"] = pred_diff\n",
    "    df[\"TRUE_DIFF\"] = true_diff\n",
    "    df[\"MARGIN_ABS\"] = np.abs(pred_diff)\n",
    "\n",
    "    # Same sign -> correct\n",
    "    df[\"OU_CORRECT\"] = (np.sign(pred_diff) == np.sign(true_diff)).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def ou_accuracy_by_season(\n",
    "    model,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    df_to_train: pd.DataFrame,\n",
    "    line_col: str = \"TOTAL_OVER_UNDER_LINE\",\n",
    "    threshold_abs: float = 0.0,\n",
    ") -> pd.DataFrame:\n",
    "    df = add_ou_correctness_columns(model, X_test, y_test, line_col=line_col)\n",
    "\n",
    "    # Bring SEASON_YEAR from your original dataframe (same pattern you used)\n",
    "    df = df.merge(df_to_train[[\"SEASON_YEAR\"]], left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "    # Apply threshold selection (margin > threshold)\n",
    "    mask = df[\"MARGIN_ABS\"] > threshold_abs\n",
    "    df_sel = df.loc[mask].copy()\n",
    "\n",
    "    season_stats = (\n",
    "        df_sel.groupby(\"SEASON_YEAR\")\n",
    "        .agg(\n",
    "            n_games=(\"OU_CORRECT\", \"size\"),\n",
    "            ou_betting_accuracy=(\"OU_CORRECT\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(\"SEASON_YEAR\")\n",
    "    )\n",
    "\n",
    "    season_stats[\"threshold_abs_pred_minus_line_gt\"] = threshold_abs\n",
    "    return season_stats\n",
    "\n",
    "# Example: threshold 0 (your current approach selects all rows with margin > 0)\n",
    "season_acc = ou_accuracy_by_season(\n",
    "    model=xgb_reg,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    df_to_train=df_to_train,\n",
    "    threshold_abs=0.0,\n",
    ")\n",
    "\n",
    "print(season_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 23:46:28,844]\u001b[0m A new study created in memory with name: no-name-4e7a048f-0ed4-4989-9506-0ddde34ecef3\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 23:48:13,472]\u001b[0m Trial 0 finished with value: 0.5623390331428632 and parameters: {'threshold_abs': 2.0, 'max_depth': 5, 'min_child_weight': 0.8219695696031055, 'gamma': 0.22800975066403162, 'subsample': 0.6803644176738863, 'colsample_bytree': 0.6115404708456444, 'learning_rate': 0.071971944311379, 'reg_alpha': 2.975656697106555e-07, 'reg_lambda': 3.478796625225186e-06, 'n_estimators': 2400}. Best is trial 0 with value: 0.5623390331428632.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 23:49:13,815]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'threshold_abs': 5.5, 'max_depth': 2, 'min_child_weight': 3.2561820715318097, 'gamma': 0.7922608676158321, 'subsample': 0.6251406533720116, 'colsample_bytree': 0.6467436280510988, 'learning_rate': 0.07385949950651723, 'reg_alpha': 0.0001507914760359121, 'reg_lambda': 4.526442350789216e-05, 'n_estimators': 1300}. Best is trial 0 with value: 0.5623390331428632.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 23:52:04,845]\u001b[0m Trial 2 finished with value: 0.5415762763728886 and parameters: {'threshold_abs': 1.0, 'max_depth': 7, 'min_child_weight': 0.9324006535234558, 'gamma': 2.360096578709636, 'subsample': 0.6572832123236058, 'colsample_bytree': 0.5216078648683131, 'learning_rate': 0.08872054229606108, 'reg_alpha': 0.0007752136208211679, 'reg_lambda': 0.8064474540618102, 'n_estimators': 2100}. Best is trial 0 with value: 0.5623390331428632.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 23:53:55,137]\u001b[0m Trial 3 finished with value: 0.5439980504804542 and parameters: {'threshold_abs': 0.5, 'max_depth': 5, 'min_child_weight': 0.015322451742059802, 'gamma': 3.4251222636135035, 'subsample': 0.7216754810066324, 'colsample_bytree': 0.7339980736899805, 'learning_rate': 0.06572206565816477, 'reg_alpha': 0.016206890107051015, 'reg_lambda': 0.0001065039713088847, 'n_estimators': 300}. Best is trial 0 with value: 0.5623390331428632.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:06:18,949]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'threshold_abs': 8.0, 'max_depth': 6, 'min_child_weight': 0.030587979357912038, 'gamma': 2.8900337278742056, 'subsample': 0.6703371360220997, 'colsample_bytree': 0.6161077437345333, 'learning_rate': 0.014398625790430934, 'reg_alpha': 2.7759840061410284e-06, 'reg_lambda': 33.17111949209411, 'n_estimators': 700}. Best is trial 0 with value: 0.5623390331428632.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:06:51,935]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:07:41,956]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:10:52,166]\u001b[0m Trial 7 finished with value: 0.5569941836407565 and parameters: {'threshold_abs': 1.0, 'max_depth': 3, 'min_child_weight': 3.221917550162143, 'gamma': 1.9693366124141598, 'subsample': 0.6695927015589098, 'colsample_bytree': 0.5767228430358106, 'learning_rate': 0.01043462061558048, 'reg_alpha': 4.6261952855941586e-05, 'reg_lambda': 0.030750251773290483, 'n_estimators': 2000}. Best is trial 0 with value: 0.5623390331428632.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:11:51,187]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:12:03,477]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:14:10,021]\u001b[0m Trial 10 finished with value: 0.4472063196291405 and parameters: {'threshold_abs': 3.0, 'max_depth': 4, 'min_child_weight': 0.10417032058255758, 'gamma': 0.032416061403772733, 'subsample': 0.5136173276929034, 'colsample_bytree': 0.8988486526273608, 'learning_rate': 0.023383877810924398, 'reg_alpha': 4.506148360821321e-08, 'reg_lambda': 0.0009699384909176453, 'n_estimators': 2500}. Best is trial 0 with value: 0.5623390331428632.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:18:03,246]\u001b[0m Trial 11 finished with value: 0.5769536753318325 and parameters: {'threshold_abs': 2.0, 'max_depth': 4, 'min_child_weight': 9.341723706425096, 'gamma': 0.044711465070548434, 'subsample': 0.9507922597821558, 'colsample_bytree': 0.6655425484006755, 'learning_rate': 0.008077146673760612, 'reg_alpha': 2.20263487010472e-06, 'reg_lambda': 0.033832473794382326, 'n_estimators': 1600}. Best is trial 11 with value: 0.5769536753318325.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:21:49,766]\u001b[0m Trial 12 finished with value: 0.5765737686676973 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 28.911177523045616, 'gamma': 0.19295242317147773, 'subsample': 0.9815846472157805, 'colsample_bytree': 0.6823527965995622, 'learning_rate': 0.008830462067384241, 'reg_alpha': 1.5279033215173693e-08, 'reg_lambda': 0.0032768993274232884, 'n_estimators': 1300}. Best is trial 11 with value: 0.5769536753318325.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:22:58,460]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:25:08,129]\u001b[0m Trial 14 finished with value: 0.5922334307321486 and parameters: {'threshold_abs': 2.5, 'max_depth': 3, 'min_child_weight': 9.459144375941168, 'gamma': 0.9826554018210272, 'subsample': 0.9995668488098411, 'colsample_bytree': 0.8385155419390147, 'learning_rate': 0.018336109697697826, 'reg_alpha': 3.094042782027701e-06, 'reg_lambda': 0.02531513772071719, 'n_estimators': 1600}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:25:47,636]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:26:27,524]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:26:58,141]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:29:11,346]\u001b[0m Trial 18 finished with value: 0.5691251203662215 and parameters: {'threshold_abs': 2.0, 'max_depth': 5, 'min_child_weight': 8.231356453001384, 'gamma': 0.6023515940680205, 'subsample': 0.9439994697881816, 'colsample_bytree': 0.7216229474496336, 'learning_rate': 0.03543360693096848, 'reg_alpha': 3.827461346788338e-07, 'reg_lambda': 0.36217266751917865, 'n_estimators': 1800}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:31:05,286]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:35:47,130]\u001b[0m Trial 20 finished with value: 0.5702440412119045 and parameters: {'threshold_abs': 2.0, 'max_depth': 4, 'min_child_weight': 11.721546084229479, 'gamma': 0.5069418432063943, 'subsample': 0.8835264239210544, 'colsample_bytree': 0.7983184337414224, 'learning_rate': 0.007609891977993582, 'reg_alpha': 8.593758482901632e-05, 'reg_lambda': 3.6793953236815518, 'n_estimators': 1800}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:38:49,631]\u001b[0m Trial 21 finished with value: 0.3769380940442791 and parameters: {'threshold_abs': 3.0, 'max_depth': 4, 'min_child_weight': 16.81580572598231, 'gamma': 0.0881654948752155, 'subsample': 0.9976790552430219, 'colsample_bytree': 0.6769865554345986, 'learning_rate': 0.009934706936558992, 'reg_alpha': 4.30088645128919e-08, 'reg_lambda': 0.005368967542828737, 'n_estimators': 1200}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:40:52,165]\u001b[0m Trial 22 finished with value: 0.5162133741505458 and parameters: {'threshold_abs': 2.5, 'max_depth': 3, 'min_child_weight': 4.822368356735926, 'gamma': 0.38828761154790525, 'subsample': 0.9517724895283898, 'colsample_bytree': 0.6825437105325901, 'learning_rate': 0.01702590959581225, 'reg_alpha': 1.2586842215277921e-06, 'reg_lambda': 0.037321657824973466, 'n_estimators': 1800}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:41:50,497]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:42:21,783]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:43:01,333]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:43:38,406]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:44:40,735]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:46:21,354]\u001b[0m Trial 28 finished with value: 0.5611252257333988 and parameters: {'threshold_abs': 1.0, 'max_depth': 2, 'min_child_weight': 5.253156570639824, 'gamma': 4.8712731106013685, 'subsample': 0.5457402516102836, 'colsample_bytree': 0.9347578509250886, 'learning_rate': 0.021987108892305575, 'reg_alpha': 1.295738305154599e-06, 'reg_lambda': 2.0061671163290675e-05, 'n_estimators': 1200}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:48:12,272]\u001b[0m Trial 29 finished with value: 0.5640634186916245 and parameters: {'threshold_abs': 1.5, 'max_depth': 5, 'min_child_weight': 0.47229656989290597, 'gamma': 0.30607093892889703, 'subsample': 0.9605020718726879, 'colsample_bytree': 0.591317176985754, 'learning_rate': 0.044765906645923684, 'reg_alpha': 1.8744890143129751e-07, 'reg_lambda': 0.11738487911763462, 'n_estimators': 1900}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:49:00,614]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:53:32,371]\u001b[0m Trial 31 finished with value: 0.57519621483147 and parameters: {'threshold_abs': 2.0, 'max_depth': 4, 'min_child_weight': 11.61753166665632, 'gamma': 0.44859738174597985, 'subsample': 0.9002023545282691, 'colsample_bytree': 0.8163698597681788, 'learning_rate': 0.00766638578330116, 'reg_alpha': 8.567427610090266e-05, 'reg_lambda': 3.009975796283656, 'n_estimators': 1800}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 00:57:45,271]\u001b[0m Trial 32 finished with value: 0.5835854752140686 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 9.304877258533793, 'gamma': 0.3280185498303596, 'subsample': 0.9190773437551978, 'colsample_bytree': 0.8079434889659113, 'learning_rate': 0.007569668905640495, 'reg_alpha': 8.924365090604133e-06, 'reg_lambda': 5.180236595049879, 'n_estimators': 1600}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:02:18,248]\u001b[0m Trial 33 finished with value: 0.5887374633210178 and parameters: {'threshold_abs': 3.0, 'max_depth': 5, 'min_child_weight': 4.762396055007341, 'gamma': 0.7459195961364624, 'subsample': 0.9439810293146896, 'colsample_bytree': 0.8588902596266134, 'learning_rate': 0.009303668139967445, 'reg_alpha': 1.0765195837254371e-06, 'reg_lambda': 9.809461803799955e-06, 'n_estimators': 1600}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:06:19,994]\u001b[0m Trial 34 finished with value: 0.5204622611380725 and parameters: {'threshold_abs': 3.0, 'max_depth': 5, 'min_child_weight': 0.8315556073226288, 'gamma': 0.8016956777129329, 'subsample': 0.9299891457047901, 'colsample_bytree': 0.8647535706675366, 'learning_rate': 0.011141091619815312, 'reg_alpha': 1.0208786239849676e-05, 'reg_lambda': 1.1502273946559184e-05, 'n_estimators': 1500}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:07:59,754]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:09:54,050]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:10:38,800]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:11:00,032]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:12:01,898]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:12:35,745]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:16:02,243]\u001b[0m Trial 41 finished with value: 0.5830731354689761 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 8.209187910969888, 'gamma': 0.2541324617457936, 'subsample': 0.9726231924199501, 'colsample_bytree': 0.6946057666153327, 'learning_rate': 0.009369079162554335, 'reg_alpha': 3.221405494262893e-08, 'reg_lambda': 0.05856996176888953, 'n_estimators': 1300}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:17:15,797]\u001b[0m Trial 42 finished with value: 0.5820948733405474 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 7.331410563456837, 'gamma': 0.35695203139299975, 'subsample': 0.9696065711392828, 'colsample_bytree': 0.7853227079004341, 'learning_rate': 0.09818332042058649, 'reg_alpha': 8.570741399466108e-07, 'reg_lambda': 0.016691880125177555, 'n_estimators': 1700}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:17:38,785]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:18:39,979]\u001b[0m Trial 44 finished with value: 0.38273561650626464 and parameters: {'threshold_abs': 3.0, 'max_depth': 3, 'min_child_weight': 0.09060840637820644, 'gamma': 0.39463193888103343, 'subsample': 0.9203426521168738, 'colsample_bytree': 0.81642208549043, 'learning_rate': 0.10707640801874815, 'reg_alpha': 6.240958628403872e-07, 'reg_lambda': 0.017659229243764073, 'n_estimators': 1300}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:19:44,003]\u001b[0m Trial 45 finished with value: 0.3097149608580186 and parameters: {'threshold_abs': 3.5, 'max_depth': 4, 'min_child_weight': 3.0511699687643534, 'gamma': 2.3435383464284385, 'subsample': 0.9631124254479871, 'colsample_bytree': 0.7060374423079736, 'learning_rate': 0.13303903622291213, 'reg_alpha': 1.0332988350424742e-07, 'reg_lambda': 0.010890336084693395, 'n_estimators': 1700}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:21:09,739]\u001b[0m Trial 46 finished with value: 0.5884495927402272 and parameters: {'threshold_abs': 2.5, 'max_depth': 3, 'min_child_weight': 11.642198159478871, 'gamma': 0.27849122691456474, 'subsample': 0.9986636607112376, 'colsample_bytree': 0.8553502407515117, 'learning_rate': 0.05661305815857901, 'reg_alpha': 6.6085592651376315e-06, 'reg_lambda': 0.0006221285157670257, 'n_estimators': 1100}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:22:24,161]\u001b[0m Trial 47 finished with value: 0.5692892589242873 and parameters: {'threshold_abs': 1.5, 'max_depth': 2, 'min_child_weight': 12.261673398170576, 'gamma': 0.23917632137672953, 'subsample': 0.9891874823480007, 'colsample_bytree': 0.854284228747122, 'learning_rate': 0.060477950742077735, 'reg_alpha': 0.0020970772597585174, 'reg_lambda': 7.714425092546886e-05, 'n_estimators': 1100}. Best is trial 14 with value: 0.5922334307321486.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:22:51,413]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:23:07,815]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:23:36,503]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:23:57,662]\u001b[0m Trial 51 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:26:11,594]\u001b[0m Trial 52 finished with value: 0.5962220187274381 and parameters: {'threshold_abs': 3.0, 'max_depth': 4, 'min_child_weight': 10.996708299797643, 'gamma': 0.024042193906469694, 'subsample': 0.9963124626133896, 'colsample_bytree': 0.8775037586277415, 'learning_rate': 0.1877475973954252, 'reg_alpha': 3.168839651924776e-07, 'reg_lambda': 4.542041014213326e-06, 'n_estimators': 1600}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:27:18,137]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:35:20,667]\u001b[0m Trial 54 finished with value: 0.5866661059071772 and parameters: {'threshold_abs': 3.0, 'max_depth': 5, 'min_child_weight': 11.206685938124737, 'gamma': 0.5649672680165485, 'subsample': 0.9389824408475238, 'colsample_bytree': 0.9608483656976745, 'learning_rate': 0.026654663934701336, 'reg_alpha': 7.444926558871645, 'reg_lambda': 2.6755211581967915e-06, 'n_estimators': 1600}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:36:07,476]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:36:50,082]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:38:46,279]\u001b[0m Trial 57 finished with value: 0.5751107247608844 and parameters: {'threshold_abs': 3.0, 'max_depth': 5, 'min_child_weight': 14.561193755948397, 'gamma': 0.6176144822525178, 'subsample': 0.9073550081959594, 'colsample_bytree': 0.9592210366179763, 'learning_rate': 0.03984519950597309, 'reg_alpha': 8.087406026149377, 'reg_lambda': 1.0636652055512092e-06, 'n_estimators': 1900}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:39:44,396]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:39:57,686]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:41:37,024]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:43:02,230]\u001b[0m Trial 61 finished with value: 0.4546165975499298 and parameters: {'threshold_abs': 3.0, 'max_depth': 4, 'min_child_weight': 6.461267072960422, 'gamma': 0.20110541528070702, 'subsample': 0.9988524961404956, 'colsample_bytree': 0.8555409391002178, 'learning_rate': 0.05298979321999714, 'reg_alpha': 2.2371494177073658e-08, 'reg_lambda': 1.312717457195902e-05, 'n_estimators': 1200}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:43:48,889]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:44:49,344]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:45:29,492]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:45:58,243]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:46:25,387]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:47:42,402]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:50:56,362]\u001b[0m Trial 68 finished with value: 0.3004717676544302 and parameters: {'threshold_abs': 3.0, 'max_depth': 4, 'min_child_weight': 0.2691495936151225, 'gamma': 0.6302178879358862, 'subsample': 0.959327158611716, 'colsample_bytree': 0.9921223671986237, 'learning_rate': 0.012849226238549573, 'reg_alpha': 3.205574853925803e-05, 'reg_lambda': 0.3136390235573079, 'n_estimators': 1800}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:54:26,851]\u001b[0m Trial 69 finished with value: 0.5215870992786765 and parameters: {'threshold_abs': 2.5, 'max_depth': 3, 'min_child_weight': 4.983757904343682, 'gamma': 1.130868397423228, 'subsample': 0.8654527816478365, 'colsample_bytree': 0.7529570428356411, 'learning_rate': 0.008188329022201664, 'reg_alpha': 3.246850038132455e-07, 'reg_lambda': 0.0038349189975257648, 'n_estimators': 1300}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:55:08,324]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:55:27,012]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:55:41,369]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:57:17,494]\u001b[0m Trial 73 finished with value: 0.3769316856540993 and parameters: {'threshold_abs': 3.5, 'max_depth': 5, 'min_child_weight': 9.326130516420537, 'gamma': 0.13181351525438578, 'subsample': 0.9328315072598825, 'colsample_bytree': 0.737003470227598, 'learning_rate': 0.06914041807470847, 'reg_alpha': 1.8826412949701882e-06, 'reg_lambda': 0.03356245673774566, 'n_estimators': 1500}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 01:57:39,073]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:01:33,038]\u001b[0m Trial 75 finished with value: 0.29631676504145166 and parameters: {'threshold_abs': 3.0, 'max_depth': 4, 'min_child_weight': 3.613023802032209, 'gamma': 0.2730858053252429, 'subsample': 0.9690180285363321, 'colsample_bytree': 0.9021864016791156, 'learning_rate': 0.010016429713451838, 'reg_alpha': 1.1080320765347962e-05, 'reg_lambda': 0.18222493242452917, 'n_estimators': 1600}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:01:50,623]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:02:41,821]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:08:15,199]\u001b[0m Trial 78 finished with value: 0.5903878497947279 and parameters: {'threshold_abs': 3.0, 'max_depth': 6, 'min_child_weight': 9.916038341433667, 'gamma': 0.5646738315790003, 'subsample': 0.9869714519050359, 'colsample_bytree': 0.8617233468041376, 'learning_rate': 0.008260261926633945, 'reg_alpha': 2.4559845439140554e-07, 'reg_lambda': 2.173220583194754e-05, 'n_estimators': 1400}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:10:07,395]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:11:52,576]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:12:56,306]\u001b[0m Trial 81 finished with value: 0.5757398165012397 and parameters: {'threshold_abs': 3.0, 'max_depth': 4, 'min_child_weight': 6.5410244696248565, 'gamma': 0.3056895550362793, 'subsample': 0.9696848769606327, 'colsample_bytree': 0.8906400338685061, 'learning_rate': 0.15716738224993865, 'reg_alpha': 4.930934384746474e-07, 'reg_lambda': 3.579116249812426e-05, 'n_estimators': 1500}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:14:46,624]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:16:10,284]\u001b[0m Trial 83 finished with value: 0.520889063085078 and parameters: {'threshold_abs': 2.5, 'max_depth': 3, 'min_child_weight': 4.553922476935083, 'gamma': 3.194801191639341, 'subsample': 0.9530543759674073, 'colsample_bytree': 0.8280584084229776, 'learning_rate': 0.05463371624991138, 'reg_alpha': 3.536404541880941e-08, 'reg_lambda': 8.826005207967556e-05, 'n_estimators': 1600}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:17:26,791]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:17:59,375]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:18:16,981]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:19:11,987]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:20:09,173]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:22:16,725]\u001b[0m Trial 89 finished with value: 0.5218423134560922 and parameters: {'threshold_abs': 3.0, 'max_depth': 5, 'min_child_weight': 7.451052766271069, 'gamma': 1.0934840881998307, 'subsample': 0.9405754596854564, 'colsample_bytree': 0.6199118073698077, 'learning_rate': 0.030456096958863352, 'reg_alpha': 8.977830762156817e-07, 'reg_lambda': 0.5941427822502943, 'n_estimators': 1800}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:23:22,710]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:24:28,259]\u001b[0m Trial 91 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:28:15,897]\u001b[0m Trial 92 finished with value: 0.5863504668600544 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 12.245165266162257, 'gamma': 0.2733970841040272, 'subsample': 0.9504798796636171, 'colsample_bytree': 0.7588175884693777, 'learning_rate': 0.00793211213445844, 'reg_alpha': 2.0051568665133593e-05, 'reg_lambda': 0.024009527248921945, 'n_estimators': 1600}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:29:29,638]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:30:42,019]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:31:34,100]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:31:55,862]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:33:27,566]\u001b[0m Trial 97 finished with value: 0.3067269931819008 and parameters: {'threshold_abs': 3.0, 'max_depth': 3, 'min_child_weight': 4.286483842931661, 'gamma': 0.12853317429165534, 'subsample': 0.9870807703304073, 'colsample_bytree': 0.7382501066513433, 'learning_rate': 0.03439308632910159, 'reg_alpha': 7.400046521449545e-06, 'reg_lambda': 0.14704362331724524, 'n_estimators': 500}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:34:25,618]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:35:46,373]\u001b[0m Trial 99 finished with value: 0.5759349218272791 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 25.738644752315775, 'gamma': 0.8358692821361957, 'subsample': 0.9553860794620227, 'colsample_bytree': 0.7704677712058803, 'learning_rate': 0.04326871400574792, 'reg_alpha': 0.010688218999506524, 'reg_lambda': 9.131153439807145e-06, 'n_estimators': 1300}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:37:07,073]\u001b[0m Trial 100 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:37:59,325]\u001b[0m Trial 101 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:41:29,154]\u001b[0m Trial 102 finished with value: 0.5857337233662664 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 14.923842799912519, 'gamma': 0.016009506773733195, 'subsample': 0.8870981540326724, 'colsample_bytree': 0.6386550005612439, 'learning_rate': 0.009773498944940133, 'reg_alpha': 1.7883932135671116e-06, 'reg_lambda': 0.05495298215403154, 'n_estimators': 1800}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:44:35,335]\u001b[0m Trial 103 finished with value: 0.5881840751217324 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 12.633966520936186, 'gamma': 0.23183875216541455, 'subsample': 0.9347542145261333, 'colsample_bytree': 0.7604756981182692, 'learning_rate': 0.010553207678746313, 'reg_alpha': 6.783971996440996e-07, 'reg_lambda': 0.012559512492685502, 'n_estimators': 2000}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:45:13,118]\u001b[0m Trial 104 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:48:13,125]\u001b[0m Trial 105 finished with value: 0.5857679159639184 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 19.86452536263511, 'gamma': 0.23620523781201683, 'subsample': 0.8934578409093235, 'colsample_bytree': 0.6923892105095646, 'learning_rate': 0.009968616491927871, 'reg_alpha': 4.561766836611746e-06, 'reg_lambda': 0.010589116682082135, 'n_estimators': 2000}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:51:36,908]\u001b[0m Trial 106 finished with value: 0.5843893226825436 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 21.148332969238947, 'gamma': 0.008600610332565206, 'subsample': 0.8468795183354301, 'colsample_bytree': 0.6294476541846286, 'learning_rate': 0.010568316580134973, 'reg_alpha': 6.5184027379532e-06, 'reg_lambda': 0.009924827910610456, 'n_estimators': 2000}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:52:27,430]\u001b[0m Trial 107 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:55:18,729]\u001b[0m Trial 108 finished with value: 0.5875644295240527 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 21.341678959921463, 'gamma': 0.19776777992072703, 'subsample': 0.8777285522455248, 'colsample_bytree': 0.6399734978916872, 'learning_rate': 0.01413242661579359, 'reg_alpha': 1.5776332244101899e-06, 'reg_lambda': 0.0033218609439221525, 'n_estimators': 2100}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 02:58:22,376]\u001b[0m Trial 109 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:03:26,911]\u001b[0m Trial 110 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:05:31,234]\u001b[0m Trial 111 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:06:16,532]\u001b[0m Trial 112 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:07:23,792]\u001b[0m Trial 113 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:08:18,966]\u001b[0m Trial 114 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:09:48,477]\u001b[0m Trial 115 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:10:28,096]\u001b[0m Trial 116 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:11:05,803]\u001b[0m Trial 117 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:12:10,382]\u001b[0m Trial 118 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:13:03,283]\u001b[0m Trial 119 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:13:46,606]\u001b[0m Trial 120 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:17:40,798]\u001b[0m Trial 121 finished with value: 0.5853302559693072 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 9.764823943957932, 'gamma': 0.4072078045602774, 'subsample': 0.9236537320332301, 'colsample_bytree': 0.855214151480139, 'learning_rate': 0.008132253626746237, 'reg_alpha': 3.24299469409906e-05, 'reg_lambda': 0.0014261740916742826, 'n_estimators': 2100}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:18:38,573]\u001b[0m Trial 122 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:22:17,176]\u001b[0m Trial 123 finished with value: 0.590676635544009 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 19.04822682481339, 'gamma': 0.6174891118479212, 'subsample': 0.9245940424490349, 'colsample_bytree': 0.8819855670422545, 'learning_rate': 0.008417031591854291, 'reg_alpha': 3.50106835519946e-06, 'reg_lambda': 0.00106824754430278, 'n_estimators': 2000}. Best is trial 52 with value: 0.5962220187274381.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:22:59,362]\u001b[0m Trial 124 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:24:31,076]\u001b[0m Trial 125 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:25:48,248]\u001b[0m Trial 126 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:27:08,263]\u001b[0m Trial 127 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:31:27,657]\u001b[0m Trial 128 finished with value: 0.6008348976729305 and parameters: {'threshold_abs': 3.0, 'max_depth': 5, 'min_child_weight': 6.764645919375405, 'gamma': 0.5555438491302327, 'subsample': 0.8997434347491664, 'colsample_bytree': 0.8777753673030719, 'learning_rate': 0.008198390348212792, 'reg_alpha': 1.5541242347086836e-06, 'reg_lambda': 0.00014480660336286608, 'n_estimators': 2200}. Best is trial 128 with value: 0.6008348976729305.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:32:31,572]\u001b[0m Trial 129 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:33:54,937]\u001b[0m Trial 130 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:38:48,184]\u001b[0m Trial 131 finished with value: 0.5765028607829902 and parameters: {'threshold_abs': 2.5, 'max_depth': 5, 'min_child_weight': 11.311609058685661, 'gamma': 0.5156952702464619, 'subsample': 0.9233824386390957, 'colsample_bytree': 0.849279707964874, 'learning_rate': 0.0079832862816855, 'reg_alpha': 4.3783784625097547e-07, 'reg_lambda': 0.00033690068095142096, 'n_estimators': 2100}. Best is trial 128 with value: 0.6008348976729305.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:41:22,291]\u001b[0m Trial 132 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:42:34,606]\u001b[0m Trial 133 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:46:24,267]\u001b[0m Trial 134 finished with value: 0.5823085252306472 and parameters: {'threshold_abs': 2.5, 'max_depth': 4, 'min_child_weight': 16.224238725243207, 'gamma': 0.4449382805872241, 'subsample': 0.9154735352088852, 'colsample_bytree': 0.8621803047833259, 'learning_rate': 0.00823514274909966, 'reg_alpha': 1.4249364434828497e-06, 'reg_lambda': 0.0005430365756598158, 'n_estimators': 2300}. Best is trial 128 with value: 0.6008348976729305.\u001b[0m\n",
      "\u001b[32m[I 2026-02-06 03:47:20,556]\u001b[0m Trial 135 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value (CV OU success): 0.6008348976729305\n",
      "Best params:\n",
      "threshold_abs 3.0\n",
      "max_depth 5\n",
      "min_child_weight 6.764645919375405\n",
      "gamma 0.5555438491302327\n",
      "subsample 0.8997434347491664\n",
      "colsample_bytree 0.8777753673030719\n",
      "learning_rate 0.008198390348212792\n",
      "reg_alpha 1.5541242347086836e-06\n",
      "reg_lambda 0.00014480660336286608\n",
      "n_estimators 2200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "LINE_COL = \"TOTAL_OVER_UNDER_LINE\"\n",
    "\n",
    "# Keep your KFold\n",
    "kf = KFold(n_splits=8, shuffle=True, random_state=16)\n",
    "\n",
    "def ou_accuracy(y_true, y_pred, line):\n",
    "    pred_diff = y_pred - line\n",
    "    true_diff = y_true - line\n",
    "    # pushes: sign(0)=0. With .5 lines it is rare anyway.\n",
    "    return float(np.mean(np.sign(pred_diff) == np.sign(true_diff)))\n",
    "\n",
    "def ou_accuracy_with_threshold(y_true, y_pred, line, threshold_abs=0.0, min_coverage=0.25):\n",
    "    margin = np.abs(y_pred - line)\n",
    "    mask = margin > threshold_abs\n",
    "    coverage = float(np.mean(mask))\n",
    "    if coverage < min_coverage:\n",
    "        # Hard penalty if the strategy barely bets\n",
    "        return 0.0, coverage\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0, coverage\n",
    "    return ou_accuracy(y_true[mask], y_pred[mask], line[mask]), coverage\n",
    "\n",
    "def _predict_best(model, X):\n",
    "    # Use best iteration if early stopping happened\n",
    "    if getattr(model, \"best_iteration\", None) is not None:\n",
    "        # Newer XGBoost\n",
    "        try:\n",
    "            return model.predict(X, iteration_range=(0, model.best_iteration + 1))\n",
    "        except TypeError:\n",
    "            # Older compatibility path\n",
    "            ntree_limit = getattr(model, \"best_ntree_limit\", None)\n",
    "            if ntree_limit is not None:\n",
    "                return model.predict(X, ntree_limit=ntree_limit)\n",
    "    return model.predict(X)\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    threshold_abs = trial.suggest_float(\"threshold_abs\", 0.0, 10.0, step=0.5)\n",
    "    min_coverage = 0.25\n",
    "\n",
    "    params = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 7),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-2, 30.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0075, 0.2, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-6, 50.0, log=True),\n",
    "\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 2500, step=100),\n",
    "        \"early_stopping_rounds\": 200,   # moved here\n",
    "        \"eval_metric\": \"rmse\",          # optional, but explicit is good\n",
    "        \"random_state\": 16,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    fold_scores = []\n",
    "    fold_coverages = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X), start=1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr = y.iloc[tr_idx].to_numpy()\n",
    "        y_va = y.iloc[va_idx].to_numpy()\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        y_pred = _predict_best(model, X_va)\n",
    "        line = X_va[LINE_COL].to_numpy()\n",
    "\n",
    "        score, coverage = ou_accuracy_with_threshold(\n",
    "            y_true=y_va,\n",
    "            y_pred=y_pred,\n",
    "            line=line,\n",
    "            threshold_abs=threshold_abs,\n",
    "            min_coverage=min_coverage,\n",
    "        )\n",
    "\n",
    "        fold_scores.append(score)\n",
    "        fold_coverages.append(coverage)\n",
    "\n",
    "        trial.report(float(np.mean(fold_scores)), step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    trial.set_user_attr(\"mean_coverage\", float(np.mean(fold_coverages)))\n",
    "    return float(np.mean(fold_scores))\n",
    "\n",
    "# ----------------------------\n",
    "# Run the search (2 to 3 hours)\n",
    "# ----------------------------\n",
    "# Make sure X_train includes TOTAL_OVER_UNDER_LINE, since you use it in the metric.\n",
    "# X_train, y_train are your current train split.\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(seed=16),\n",
    "    pruner=MedianPruner(n_warmup_steps=2),\n",
    ")\n",
    "\n",
    "# Time budget: 3 hours. You can adjust to 2*3600 if you want.\n",
    "study.optimize(lambda t: objective(t, X_train, y_train), timeout=4 * 3600, n_jobs=1)\n",
    "\n",
    "print(\"Best value (CV OU success):\", study.best_value)\n",
    "print(\"Best params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(k, v)\n",
    "\n",
    "# ----------------------------\n",
    "# Train final model on full train set\n",
    "# ----------------------------\n",
    "best_params = study.best_params.copy()\n",
    "best_threshold = best_params.pop(\"threshold_abs\")  # strategy threshold\n",
    "\n",
    "final_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"random_state\": 16,\n",
    "    \"n_jobs\": -1,\n",
    "    **best_params,\n",
    "}\n",
    "\n",
    "final_model = XGBRegressor(**final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ou_xgb_bundle.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "final_model.fit(X_train, y_train, verbose=False)\n",
    "final_model.save_model(\"xgb_ou_model.json\")   # or .ubj in newer versions\n",
    "\n",
    "\n",
    "bundle = {\n",
    "    \"model\": final_model,\n",
    "    \"threshold_abs\": best_threshold,\n",
    "    \"feature_names\": list(X_train.columns),\n",
    "    \"line_col\": LINE_COL,\n",
    "}\n",
    "joblib.dump(bundle, \"ou_xgb_bundle.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check in Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_92e67\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_92e67_level0_col0\" class=\"col_heading level0 col0\" >threshold_abs_pred_minus_line_gt</th>\n",
       "      <th id=\"T_92e67_level0_col1\" class=\"col_heading level0 col1\" >n_games</th>\n",
       "      <th id=\"T_92e67_level0_col2\" class=\"col_heading level0 col2\" >pct_of_test</th>\n",
       "      <th id=\"T_92e67_level0_col3\" class=\"col_heading level0 col3\" >ou_betting_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_92e67_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_92e67_row0_col1\" class=\"data row0 col1\" >1994</td>\n",
       "      <td id=\"T_92e67_row0_col2\" class=\"data row0 col2\" >100.0%</td>\n",
       "      <td id=\"T_92e67_row0_col3\" class=\"data row0 col3\" >52.51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_92e67_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_92e67_row1_col1\" class=\"data row1 col1\" >1589</td>\n",
       "      <td id=\"T_92e67_row1_col2\" class=\"data row1 col2\" >79.7%</td>\n",
       "      <td id=\"T_92e67_row1_col3\" class=\"data row1 col3\" >53.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_92e67_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_92e67_row2_col1\" class=\"data row2 col1\" >1217</td>\n",
       "      <td id=\"T_92e67_row2_col2\" class=\"data row2 col2\" >61.0%</td>\n",
       "      <td id=\"T_92e67_row2_col3\" class=\"data row2 col3\" >53.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_92e67_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_92e67_row3_col1\" class=\"data row3 col1\" >895</td>\n",
       "      <td id=\"T_92e67_row3_col2\" class=\"data row3 col2\" >44.9%</td>\n",
       "      <td id=\"T_92e67_row3_col3\" class=\"data row3 col3\" >55.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_92e67_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_92e67_row4_col1\" class=\"data row4 col1\" >660</td>\n",
       "      <td id=\"T_92e67_row4_col2\" class=\"data row4 col2\" >33.1%</td>\n",
       "      <td id=\"T_92e67_row4_col3\" class=\"data row4 col3\" >56.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_92e67_row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "      <td id=\"T_92e67_row5_col1\" class=\"data row5 col1\" >465</td>\n",
       "      <td id=\"T_92e67_row5_col2\" class=\"data row5 col2\" >23.3%</td>\n",
       "      <td id=\"T_92e67_row5_col3\" class=\"data row5 col3\" >57.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_92e67_row6_col0\" class=\"data row6 col0\" >6</td>\n",
       "      <td id=\"T_92e67_row6_col1\" class=\"data row6 col1\" >307</td>\n",
       "      <td id=\"T_92e67_row6_col2\" class=\"data row6 col2\" >15.4%</td>\n",
       "      <td id=\"T_92e67_row6_col3\" class=\"data row6 col3\" >59.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_92e67_row7_col0\" class=\"data row7 col0\" >7</td>\n",
       "      <td id=\"T_92e67_row7_col1\" class=\"data row7 col1\" >209</td>\n",
       "      <td id=\"T_92e67_row7_col2\" class=\"data row7 col2\" >10.5%</td>\n",
       "      <td id=\"T_92e67_row7_col3\" class=\"data row7 col3\" >62.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_92e67_row8_col0\" class=\"data row8 col0\" >8</td>\n",
       "      <td id=\"T_92e67_row8_col1\" class=\"data row8 col1\" >146</td>\n",
       "      <td id=\"T_92e67_row8_col2\" class=\"data row8 col2\" >7.3%</td>\n",
       "      <td id=\"T_92e67_row8_col3\" class=\"data row8 col3\" >65.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_92e67_row9_col0\" class=\"data row9 col0\" >9</td>\n",
       "      <td id=\"T_92e67_row9_col1\" class=\"data row9 col1\" >111</td>\n",
       "      <td id=\"T_92e67_row9_col2\" class=\"data row9 col2\" >5.6%</td>\n",
       "      <td id=\"T_92e67_row9_col3\" class=\"data row9 col3\" >68.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92e67_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_92e67_row10_col0\" class=\"data row10 col0\" >10</td>\n",
       "      <td id=\"T_92e67_row10_col1\" class=\"data row10 col1\" >85</td>\n",
       "      <td id=\"T_92e67_row10_col2\" class=\"data row10 col2\" >4.3%</td>\n",
       "      <td id=\"T_92e67_row10_col3\" class=\"data row10 col3\" >75.29%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7685fc147fe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df_final, y_pred_test = evaluate_ou_thresholds(\n",
    "    model=final_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    thresholds=range(0, 11)  # 0..10\n",
    ")\n",
    "\n",
    "# Pretty display\n",
    "display(results_df_final.style.format({\n",
    "    \"pct_of_test\": \"{:.1%}\",\n",
    "    \"ou_betting_accuracy\": \"{:.2%}\",\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "e6aa374f-7c0f-4b0e-9a9c-58412a8decba",
       "rows": [
        [
         "0",
         "total_draftkings_line_over",
         "0.04222045"
        ],
        [
         "1",
         "total_fanduel_line_over",
         "0.020680998"
        ],
        [
         "2",
         "odds_total_line_books_mean",
         "0.019865893"
        ],
        [
         "3",
         "TOTAL_OVER_UNDER_LINE",
         "0.005469913"
        ],
        [
         "4",
         "IMPLIED_PTS_HOME",
         "0.0030965435"
        ],
        [
         "5",
         "TOP6_INJURED_PLAYER_MIN_BEFORE_TEAM_AWAY",
         "0.0030502058"
        ],
        [
         "6",
         "IS_OVER_LINE_LAST_HOME_AWAY_5_MATCHES_BEFORE_TEAM_HOME",
         "0.002839736"
        ],
        [
         "7",
         "TOP4_PLAYER_PACE_PER40_BEFORE_TEAM_AWAY",
         "0.002469673"
        ],
        [
         "8",
         "TOP5_INJURED_PLAYER_TS_PCT_BEFORE_TEAM_HOME",
         "0.002384572"
        ],
        [
         "9",
         "odds_ml_away_prob_novig_fanduel",
         "0.0023599833"
        ],
        [
         "10",
         "ml_fanduel_price_home",
         "0.0023004748"
        ],
        [
         "11",
         "MONEYLINE_TEAM_AWAY",
         "0.0022973474"
        ],
        [
         "12",
         "TOP5_INJURED_PLAYER_OFF_RATING_BEFORE_TEAM_AWAY",
         "0.0022593634"
        ],
        [
         "13",
         "ml_consensus_opener_price_home",
         "0.0022404646"
        ],
        [
         "14",
         "MONEYLINE_TEAM_HOME",
         "0.002179946"
        ],
        [
         "15",
         "IMPLIED_PTS_AWAY",
         "0.0021300307"
        ],
        [
         "16",
         "total_caesars_line_over",
         "0.0021212264"
        ],
        [
         "17",
         "TOP5_PLAYER_PACE_PER40_BEFORE_TEAM_AWAY",
         "0.0020854424"
        ],
        [
         "18",
         "TOP3_ABSENCE_EFFECT_AWAY_P2_TOTAL_POINTS",
         "0.0020704952"
        ],
        [
         "19",
         "TOP1_PLAYER_MIN_BEFORE_TEAM_AWAY",
         "0.0020351782"
        ],
        [
         "20",
         "TOP3_PLAYER_PACE_PER40_BEFORE_TEAM_AWAY",
         "0.0020302644"
        ],
        [
         "21",
         "total_consensus_pct_under__is_missing",
         "0.002022826"
        ],
        [
         "22",
         "ml_draftkings_price_home",
         "0.002001299"
        ],
        [
         "23",
         "odds_total_line_books_mean_minus_opener",
         "0.0019636708"
        ],
        [
         "24",
         "SPREAD_SEASON_BEFORE_AVG_TEAM_AWAY",
         "0.0019524562"
        ],
        [
         "25",
         "spread_caesars_price_home",
         "0.0019363726"
        ],
        [
         "26",
         "FG3M_LAST_HOME_AWAY_10_MATCHES_BEFORE_TEAM_HOME",
         "0.0019237323"
        ],
        [
         "27",
         "spread_consensus_opener_line_home",
         "0.0019136945"
        ],
        [
         "28",
         "TOP3_INJURED_PLAYER_PTS_BEFORE_TEAM_AWAY",
         "0.0019111878"
        ],
        [
         "29",
         "TOP3_ABSENCE_EFFECT_HOME_P4_TOTAL_POINTS",
         "0.0018673376"
        ],
        [
         "30",
         "BACK_TO_BACK",
         "0.0018666431"
        ],
        [
         "31",
         "STAR_PTS_PCT_DIFF_HOME_MINUS_AWAY",
         "0.0018663516"
        ],
        [
         "32",
         "PIE_SEASON_BEFORE_AVG_TEAM_HOME",
         "0.0018633101"
        ],
        [
         "33",
         "odds_total_line_move_draftkings",
         "0.0018569783"
        ],
        [
         "34",
         "TOP8_PLAYER_TS_PCT_BEFORE_TEAM_HOME",
         "0.0018530493"
        ],
        [
         "35",
         "REF_TRIO_DIFFERENCE_FROM_LINE_DIFF_BEFORE",
         "0.0018454815"
        ],
        [
         "36",
         "TOP4_PLAYER_PACE_PER40_BEFORE_TEAM_HOME",
         "0.00183312"
        ],
        [
         "37",
         "spread_consensus_opener_price_home",
         "0.0018313921"
        ],
        [
         "38",
         "TOP4_INJURED_PLAYER_MIN_BEFORE_TEAM_HOME",
         "0.0018135626"
        ],
        [
         "39",
         "SAME_CONFERENCE",
         "0.0018133825"
        ],
        [
         "40",
         "ml_betmgm_price_home",
         "0.0018119783"
        ],
        [
         "41",
         "TOP3_INJURED_PLAYER_TS_PCT_BEFORE_TEAM_HOME",
         "0.0018074311"
        ],
        [
         "42",
         "odds_ml_bets_skew_home_minus_away",
         "0.0018026849"
        ],
        [
         "43",
         "TOP1_INJURED_PLAYER_TS_PCT_BEFORE_TEAM_HOME",
         "0.0018013584"
        ],
        [
         "44",
         "DIFF_FROM_LINE_LAST_ALL_3_MATCHES_BEFORE_TEAM_AWAY",
         "0.0018005596"
        ],
        [
         "45",
         "REST_DAYS_BEFORE_MATCH_TEAM_HOME",
         "0.0017898022"
        ],
        [
         "46",
         "TOP4_INJURED_PLAYER_OFF_RATING_BEFORE_TEAM_AWAY",
         "0.0017720952"
        ],
        [
         "47",
         "POSS_SEASON_BEFORE_AVG_TEAM_HOME",
         "0.0017648684"
        ],
        [
         "48",
         "TOTAL_KM_IN_LAST_1_DAYS_HOME_TEAM",
         "0.0017641445"
        ],
        [
         "49",
         "odds_total_line_move_fanduel",
         "0.0017630846"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 739
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total_draftkings_line_over</td>\n",
       "      <td>0.042220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_fanduel_line_over</td>\n",
       "      <td>0.020681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odds_total_line_books_mean</td>\n",
       "      <td>0.019866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOTAL_OVER_UNDER_LINE</td>\n",
       "      <td>0.005470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMPLIED_PTS_HOME</td>\n",
       "      <td>0.003097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>spread_betmgm_price_away__is_missing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>spread_betmgm_line_home__is_missing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>spread_betmgm_price_home__is_missing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>total_fanduel_line_over__is_missing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>total_fanduel_price_under__is_missing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Feature  Importance\n",
       "0               total_draftkings_line_over    0.042220\n",
       "1                  total_fanduel_line_over    0.020681\n",
       "2               odds_total_line_books_mean    0.019866\n",
       "3                    TOTAL_OVER_UNDER_LINE    0.005470\n",
       "4                         IMPLIED_PTS_HOME    0.003097\n",
       "..                                     ...         ...\n",
       "686   spread_betmgm_price_away__is_missing    0.000000\n",
       "687    spread_betmgm_line_home__is_missing    0.000000\n",
       "688   spread_betmgm_price_home__is_missing    0.000000\n",
       "737    total_fanduel_line_over__is_missing    0.000000\n",
       "738  total_fanduel_price_under__is_missing    0.000000\n",
       "\n",
       "[739 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = final_model.feature_importances_\n",
    "important_features = np.argsort(feature_importances)[::-1]  \n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns[important_features],\n",
    "    'Importance': feature_importances[important_features]\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

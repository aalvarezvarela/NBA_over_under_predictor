{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f347530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from nba_ou.prediction.clean_data_before_prediction import prepare_training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a68e4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2148 odds records from database\n",
      "Loading NBA data from PostgreSQL...\n",
      "Loaded 4299 game records from database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/odds/process_odds_data.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_odds.sort_values(by=[\"game_date\", \"team_home\"], ascending=False, inplace=True)\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/odds/process_odds_data.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_odds_processed[\"SPREAD_AWAY\"] = -df_odds_processed[\"SPREAD_HOME\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 58130 player records from database\n",
      "Successfully loaded 4299 games and 58130 player records\n",
      "Loading data for seasons: ['2024-25', '2025-26']\n",
      "Found 32 rows with potential home/away parsing errors.\n",
      "Fixed HOME column for 32 problematic rows.\n",
      "Overtime adjustments completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing rolling stats: 100%|██████████| 25/25 [00:16<00:00,  1.56it/s]\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/postgre_db/injuries_refs/fetch_injury_db/get_injury_data_from_db.py:37: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_injuries = pd.read_sql_query(query, conn, params=(season_years,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17564 injury records from database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding players data: 100%|██████████| 3998/3998 [01:27<00:00, 45.44it/s] \n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/players/attach_player_features.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_team[\"TOTAL_INJURED_PLAYER_PTS_BEFORE\"] = (\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/merged_home_away_data/merge_home_away.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"STAR_OFFENSIVE_RATIO_IMPROVEMENT_BEFORE\"] = (\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/merged_home_away_data/merge_home_away.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"STAR_PTS_PERCENTAGE_BEFORE\"] = (\n",
      "100%|██████████| 1999/1999 [00:02<00:00, 841.47it/s]\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/postgre_db/injuries_refs/fetch_refs_db/get_refs_db.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_refs = pd.read_sql_query(query, conn, params=(season_years,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6521 referee records from database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing referee features: 100%|██████████| 1999/1999 [00:43<00:00, 45.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Referee features successfully merged into training data!\n",
      "Training data shape after merge: (1999, 994)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing absence effects: 100%|██████████| 1999/1999 [00:35<00:00, 55.55it/s]\n",
      "Computing absence effects: 100%|██████████| 1999/1999 [00:29<00:00, 67.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing travel features...\n",
      "Travel features computed successfully.\n",
      "\n",
      "----------------------------------------\n",
      "Training data created up to 2026-01-24 00:00:00\n",
      "Number of games: 1999\n",
      "Number of features: 973\n",
      "----------------------------------------\n",
      "\n",
      "Loaded 2148 odds records from database\n",
      "Loading NBA data from PostgreSQL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/postgre_db/games/fetch_data_from_db/fetch_data_from_games_db.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn, params=(season_years,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4299 game records from database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/postgre_db/players/fetch_players_data_from_db.py:36: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn, params=(season_years,))\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/odds/process_odds_data.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_odds.sort_values(by=[\"game_date\", \"team_home\"], ascending=False, inplace=True)\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/odds/process_odds_data.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_odds_processed[\"SPREAD_AWAY\"] = -df_odds_processed[\"SPREAD_HOME\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 58130 player records from database\n",
      "Successfully loaded 4299 games and 58130 player records\n",
      "Loading data for seasons: ['2024-25', '2025-26']\n",
      "Found 28 rows with potential home/away parsing errors.\n",
      "Fixed HOME column for 28 problematic rows.\n",
      "Overtime adjustments completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing rolling stats: 100%|██████████| 25/25 [00:11<00:00,  2.10it/s]\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/postgre_db/injuries_refs/fetch_injury_db/get_injury_data_from_db.py:37: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_injuries = pd.read_sql_query(query, conn, params=(season_years,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17564 injury records from database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding players data: 100%|██████████| 3646/3646 [01:05<00:00, 55.66it/s] \n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/players/attach_player_features.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_team[\"TOTAL_INJURED_PLAYER_PTS_BEFORE\"] = (\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/merged_home_away_data/merge_home_away.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"STAR_OFFENSIVE_RATIO_IMPROVEMENT_BEFORE\"] = (\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/data_preparation/merged_home_away_data/merge_home_away.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"STAR_PTS_PERCENTAGE_BEFORE\"] = (\n",
      "100%|██████████| 1823/1823 [00:01<00:00, 932.37it/s]\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/postgre_db/injuries_refs/fetch_refs_db/get_refs_db.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_refs = pd.read_sql_query(query, conn, params=(season_years,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6521 referee records from database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing referee features: 100%|██████████| 1823/1823 [00:29<00:00, 62.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Referee features successfully merged into training data!\n",
      "Training data shape after merge: (1823, 994)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing absence effects: 100%|██████████| 1823/1823 [00:30<00:00, 59.41it/s]\n",
      "Computing absence effects: 100%|██████████| 1823/1823 [00:23<00:00, 76.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing travel features...\n",
      "Travel features computed successfully.\n",
      "\n",
      "----------------------------------------\n",
      "Training data created up to 2026-01-01 00:00:00\n",
      "Number of games: 1823\n",
      "Number of features: 973\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nba_ou.create_training_data.create_df_to_predict import create_df_to_predict\n",
    "# Create training data up to a specific date\n",
    "date_to_train_1 = \"2026-01-24\"\n",
    "\n",
    "safe_limit = \"2024-10-11\"  # Optional: specify start date\n",
    "\n",
    "\n",
    "df_total_1 = create_df_to_predict(\n",
    "    recent_limit_to_include=date_to_train_1, older_limit_to_include=safe_limit\n",
    ")\n",
    "\n",
    "date_to_train_2 = \"2026-01-01\"\n",
    "\n",
    "df_total_2 = create_df_to_predict(\n",
    "    recent_limit_to_include=date_to_train_2, older_limit_to_include=safe_limit\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5921cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1653672/2166285095.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eval_1['OVER_UNDER'] = np.where(df_eval_1['TOTAL_POINTS'] >= df_eval_1['TOTAL_OVER_UNDER_LINE'], 1, 0)\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/prediction/clean_data_before_prediction.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stats.dropna(subset=[total_line_col], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "older_limit_to_include = \"2025-12-16\" # Optional: specify start date\n",
    "max_limit_date = \"2026-01-01\" \n",
    "\n",
    "df_total_1['GAME_DATE'] = pd.to_datetime(df_total_1['GAME_DATE'])\n",
    "df_eval_1 = df_total_1[(df_total_1['GAME_DATE'] >= pd.to_datetime(older_limit_to_include)) & (df_total_1['GAME_DATE'] <= pd.to_datetime(max_limit_date))]\n",
    "df_eval_1['OVER_UNDER'] = np.where(df_eval_1['TOTAL_POINTS'] >= df_eval_1['TOTAL_OVER_UNDER_LINE'], 1, 0)\n",
    "df_eval_1 = prepare_training_dataframe(df_eval_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "985b42db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1653672/3351790841.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eval_2['OVER_UNDER'] = np.where(df_eval_2['TOTAL_POINTS'] >= df_eval_2['TOTAL_OVER_UNDER_LINE'], 1, 0)\n",
      "/home/adrian_alvarez/Projects/NBA_over_under_predictor/src/nba_ou/prediction/clean_data_before_prediction.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stats.dropna(subset=[total_line_col], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "older_limit_to_include = \"2025-12-16\" # Optional: specify start date\n",
    "max_limit_date = \"2026-01-01\" \n",
    "\n",
    "df_total_2['GAME_DATE'] = pd.to_datetime(df_total_2['GAME_DATE'])\n",
    "df_eval_2 = df_total_2[(df_total_2['GAME_DATE'] >= pd.to_datetime(older_limit_to_include)) & (df_total_2['GAME_DATE'] <= pd.to_datetime(max_limit_date))]\n",
    "df_eval_2['OVER_UNDER'] = np.where(df_eval_2['TOTAL_POINTS'] >= df_eval_2['TOTAL_OVER_UNDER_LINE'], 1, 0)\n",
    "df_eval_2 = prepare_training_dataframe(df_eval_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcb940",
   "metadata": {},
   "source": [
    "# Predicitons Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42e92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor.load(\"/home/adrian_alvarez/Projects/NBA_over_under_predictor/models/classifier_autoglue_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "943dbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = df_eval_1.drop(columns=['OVER_UNDER', 'TOTAL_POINTS'])\n",
    "y_test = df_eval_1['OVER_UNDER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f28c03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "832e8477-e8de-41b6-a75c-bf78d9e1e94f",
       "rows": [
        [
         "176",
         "0"
        ],
        [
         "177",
         "1"
        ],
        [
         "178",
         "1"
        ],
        [
         "179",
         "0"
        ],
        [
         "180",
         "1"
        ],
        [
         "181",
         "0"
        ],
        [
         "182",
         "0"
        ],
        [
         "183",
         "1"
        ],
        [
         "184",
         "1"
        ],
        [
         "185",
         "0"
        ],
        [
         "186",
         "1"
        ],
        [
         "187",
         "0"
        ],
        [
         "188",
         "0"
        ],
        [
         "189",
         "1"
        ],
        [
         "190",
         "1"
        ],
        [
         "191",
         "1"
        ],
        [
         "192",
         "1"
        ],
        [
         "193",
         "0"
        ],
        [
         "194",
         "1"
        ],
        [
         "195",
         "0"
        ],
        [
         "196",
         "1"
        ],
        [
         "197",
         "1"
        ],
        [
         "198",
         "1"
        ],
        [
         "199",
         "0"
        ],
        [
         "200",
         "1"
        ],
        [
         "201",
         "0"
        ],
        [
         "202",
         "1"
        ],
        [
         "203",
         "1"
        ],
        [
         "204",
         "1"
        ],
        [
         "205",
         "1"
        ],
        [
         "206",
         "1"
        ],
        [
         "207",
         "1"
        ],
        [
         "208",
         "0"
        ],
        [
         "209",
         "1"
        ],
        [
         "210",
         "1"
        ],
        [
         "211",
         "1"
        ],
        [
         "212",
         "1"
        ],
        [
         "213",
         "1"
        ],
        [
         "214",
         "0"
        ],
        [
         "215",
         "0"
        ],
        [
         "216",
         "1"
        ],
        [
         "217",
         "0"
        ],
        [
         "218",
         "1"
        ],
        [
         "219",
         "1"
        ],
        [
         "220",
         "0"
        ],
        [
         "221",
         "1"
        ],
        [
         "222",
         "1"
        ],
        [
         "224",
         "0"
        ],
        [
         "225",
         "1"
        ],
        [
         "226",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 111
       }
      },
      "text/plain": [
       "176    0\n",
       "177    1\n",
       "178    1\n",
       "179    0\n",
       "180    1\n",
       "      ..\n",
       "285    1\n",
       "286    1\n",
       "287    0\n",
       "288    1\n",
       "289    1\n",
       "Name: target, Length: 111, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = predictor.predict(df_predict)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea248ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "80ebe63d-7328-46d5-b2a0-c6b56ddec2db",
       "rows": [
        [
         "accuracy",
         "0.5315"
        ],
        [
         "balanced_accuracy",
         "0.5388"
        ],
        [
         "precision",
         "0.5"
        ],
        [
         "recall",
         "0.6538"
        ],
        [
         "f1",
         "0.5667"
        ],
        [
         "error_rate",
         "0.4685"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "accuracy             0.5315\n",
       "balanced_accuracy    0.5388\n",
       "precision            0.5000\n",
       "recall               0.6538\n",
       "f1                   0.5667\n",
       "error_rate           0.4685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(y_test, y_test_pred),\n",
    "    \"precision\": precision_score(y_test, y_test_pred),\n",
    "    \"recall\": recall_score(y_test, y_test_pred),\n",
    "    \"f1\": f1_score(y_test, y_test_pred),\n",
    "    \"error_rate\": 1 - accuracy_score(y_test, y_test_pred),\n",
    "}\n",
    "\n",
    "pd.Series(metrics).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440d12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_2 = df_eval_2.drop(columns=['OVER_UNDER', 'TOTAL_POINTS'])\n",
    "y_test_2 = df_eval_2['OVER_UNDER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c616c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f08f0656-33a2-4e93-801b-2314bff5fb1b",
       "rows": [
        [
         "0",
         "1"
        ],
        [
         "1",
         "1"
        ],
        [
         "2",
         "0"
        ],
        [
         "3",
         "0"
        ],
        [
         "4",
         "1"
        ],
        [
         "5",
         "0"
        ],
        [
         "6",
         "0"
        ],
        [
         "7",
         "1"
        ],
        [
         "8",
         "0"
        ],
        [
         "9",
         "0"
        ],
        [
         "10",
         "1"
        ],
        [
         "11",
         "1"
        ],
        [
         "12",
         "0"
        ],
        [
         "13",
         "1"
        ],
        [
         "14",
         "1"
        ],
        [
         "15",
         "0"
        ],
        [
         "16",
         "1"
        ],
        [
         "17",
         "1"
        ],
        [
         "18",
         "1"
        ],
        [
         "19",
         "1"
        ],
        [
         "20",
         "1"
        ],
        [
         "21",
         "1"
        ],
        [
         "22",
         "1"
        ],
        [
         "23",
         "1"
        ],
        [
         "24",
         "0"
        ],
        [
         "25",
         "0"
        ],
        [
         "26",
         "1"
        ],
        [
         "27",
         "0"
        ],
        [
         "28",
         "1"
        ],
        [
         "29",
         "1"
        ],
        [
         "30",
         "1"
        ],
        [
         "31",
         "1"
        ],
        [
         "32",
         "1"
        ],
        [
         "33",
         "0"
        ],
        [
         "34",
         "1"
        ],
        [
         "35",
         "1"
        ],
        [
         "36",
         "1"
        ],
        [
         "37",
         "1"
        ],
        [
         "38",
         "0"
        ],
        [
         "39",
         "1"
        ],
        [
         "40",
         "1"
        ],
        [
         "41",
         "0"
        ],
        [
         "42",
         "0"
        ],
        [
         "43",
         "1"
        ],
        [
         "45",
         "1"
        ],
        [
         "46",
         "1"
        ],
        [
         "47",
         "0"
        ],
        [
         "48",
         "0"
        ],
        [
         "49",
         "0"
        ],
        [
         "50",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 111
       }
      },
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "109    1\n",
       "110    0\n",
       "111    0\n",
       "112    1\n",
       "113    1\n",
       "Name: target, Length: 111, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_2 = predictor.predict(df_predict_2)\n",
    "y_test_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f5e524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f9e1f671-0286-4e29-9d88-f4d03373bdb3",
       "rows": [
        [
         "accuracy",
         "0.5315"
        ],
        [
         "balanced_accuracy",
         "0.5388"
        ],
        [
         "precision",
         "0.5"
        ],
        [
         "recall",
         "0.6538"
        ],
        [
         "f1",
         "0.5667"
        ],
        [
         "error_rate",
         "0.4685"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "accuracy             0.5315\n",
       "balanced_accuracy    0.5388\n",
       "precision            0.5000\n",
       "recall               0.6538\n",
       "f1                   0.5667\n",
       "error_rate           0.4685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_2 = {\n",
    "    \"accuracy\": accuracy_score(y_test_2, y_test_pred_2),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(y_test_2, y_test_pred_2),\n",
    "    \"precision\": precision_score(y_test_2, y_test_pred_2),\n",
    "    \"recall\": recall_score(y_test_2, y_test_pred_2),\n",
    "    \"f1\": f1_score(y_test_2, y_test_pred_2),\n",
    "    \"error_rate\": 1 - accuracy_score(y_test_2, y_test_pred_2),\n",
    "}\n",
    "\n",
    "pd.Series(metrics_2).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88989cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4cf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20ff42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
